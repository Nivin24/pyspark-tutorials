# DataFrame Operations in PySpark

## Overview
This folder contains tutorials on working with Spark DataFrames - the main data abstraction in modern PySpark.

## Topics Covered

1. **01_creating_dataframes.py** - Creating DataFrames from various sources
2. **02_dataframe_operations.py** - Selecting, renaming, and transforming columns
3. **03_filtering_and_selection.py** - Filtering rows and selecting specific columns
4. **04_aggregations.py** - Aggregation functions and statistics
5. **05_joins.py** - Joining DataFrames (inner, outer, cross)
6. **06_groupby_and_windows.py** - Group by operations and window functions

## Learning Objectives

- Create DataFrames from different data sources
- Perform DataFrame transformations and filtering
- Execute aggregations and statistical operations
- Combine DataFrames using joins
- Apply window functions for advanced analytics

## Key DataFrame Operations

- `select()` - Select specific columns
- `filter()` - Filter rows based on conditions
- `groupBy()` - Group data for aggregations
- `join()` - Combine DataFrames
- `agg()` - Aggregate functions
- `window()` - Window functions
- `withColumn()` - Add or modify columns

## Prerequisites

- Understand Spark fundamentals (RDDs, lazy evaluation)
- Knowledge of Spark Session setup
- Basic SQL understanding

## Next Steps
After completing this section, move to `03_sql/` for advanced SQL operations.
